{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b713a1cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4256529330.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    take the initial prompt + teh guidance slacing of teh difference between the unconditioned - teh conditional\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pred = u = g * (t - u)\n",
    "\n",
    "take the initial prompt + teh guidance slacing of teh difference between the unconditioned - teh conditional\n",
    "\n",
    "# torch.norm(t - u) * torch.norm(u)\n",
    "\n",
    "# Then we can can rescale the difference and the results\n",
    "# If you take the guidance_scale which is constant by the value that you set - you can instead provide a cosine guidance_scale\n",
    "# then once the model knows which kind of image it is trying to draw you can let it become far more detailed and provide its own imgae instead of being restrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a349190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ? and ?? at the end of a method or function to show the docs and source code in order to understand how it all works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020d56ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DiffEdit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DiffEdit \u001b[38;5;241m-\u001b[39m Diffusion\u001b[38;5;241m-\u001b[39mbased\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DiffEdit' is not defined"
     ]
    }
   ],
   "source": [
    "DiffEdit - Diffusion-based \n",
    "# text-condiitoned diffusion models (semantic image editing)\n",
    "# L2-norm - means the root sum of squares - squared which is just the sum of squares\n",
    "# The loss is the Expectation of the sum of square differences between values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074d762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The expected value is the total possibilities times by the probability of actually getting that value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function is the mean squared error that is the expected value of hte difference between the noise adn the noise estimation,\n",
    "# where we reduce teh vlaue of each pixel and then add noise to each pixel.\n",
    "# the coefficient alpha is a function of noise and is a decreasing function\n",
    "# if we give an incorrect query such as zebra and provide it to teh model it will addd the noise to the place where the horse is and thsus will add the mask to the\n",
    "# inference on hte model - the lying version that does not match it must be noise\n",
    "# difference between both predictions is the actual thing that needs to be changed and thus provides a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17401360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(1)\n",
    "weights = torch.randn(784, 10)\n",
    "bias = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1489e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 is the combination matrix of all 5 images with the pixels that have all been shrinked\n",
    "# m2 is the nerual network with all of the weights that dictate whether a image is part of a given value or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a27d82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ar):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(bc):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ac):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ar' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(ar):\n",
    "    for j in range(bc):\n",
    "        for k in range(ac):\n",
    "            t1[i, j] = m1[i, k] * m2[k, j]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c86f6661",
   "metadata": {},
   "source": [
    "torch.set_printoptions(linewidth = 140)\n",
    "# this will allow you to chagne the line width to make it far easier to read - can put it at the top of the notebooks\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbda - takes python and turns it into machine code \n",
    "from numbda import njit\n",
    "# we can make python run at c speed by optimising compiled code\n",
    "\n",
    "@njit\n",
    "def dot(a, b):\n",
    "    res = 0\n",
    "    for i in range(len(a)):\n",
    "        res += a[i] * b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91516a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "a = tensor([10., 6., -4])\n",
    "b = tensor([2., 8., 7.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b7b761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 14.,  3.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef5096a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a < b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfad984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The frobenius norm is the squared values summed and then square rooted\n",
    "fn = (m * m).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting\n",
    "\n",
    "# How arrays with different shapes are able to apply arithmetic operations\n",
    "# stride means taht it acts as if it is a 3x3 matrix, and when it acts as if it goes to the next row it actually stays the exact same\n",
    "# numpy makes this very very efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsqueeze() in pytorch allows us to create an additional dimensional\n",
    "# such as np.newaxis\n",
    "# this can be done by indexing into a column using None\n",
    "c.unsqueeze(0) == c[None, :]\n",
    "# they both allow us to convert from a vector of size 3 to a shape of 1, 3\n",
    "# c[None] will also give you an extra dimension\n",
    "# c[..., None].shape will also work \n",
    "# np.newaxis is also quite useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ec1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .expand_as(m) means that we will expand our current matrix to the size of some other matrix\n",
    "# we cna also expand using None\n",
    "# after we expand using None for both rows nad columns we can multiply both new matrices that are 3 * 1 and 1 * 3 to make a 3 * 3 matrix\n",
    "\n",
    "# By using this kind of broadcasting we no longer need to do any minibatching since it is so fast that it no longer needs to be slowly applied"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
