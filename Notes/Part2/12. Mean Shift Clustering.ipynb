{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e257a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP interrogator\n",
    "# you input an image and it will output an existing answer\n",
    "\n",
    "# CLIP image encoder - encodes the image and then will provide an embedding of an output all you ahve to do is decode this embedding\n",
    "# diffusion takes an embedding and inverts and encoder to add noise and slowly try to approximate this value\n",
    "# stable diffusion tries to approximate inverse problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a04c841",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Einstein summations\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# compact representation for representing products and sums\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mik, kj -> ikj\u001b[39m\u001b[38;5;124m'\u001b[39m, m1, m2)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# if we instead want to sum automatically we can simply write\u001b[39;00m\n\u001b[0;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mik, kj -> ij\u001b[39m\u001b[38;5;124m'\u001b[39m, m1, m2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Einstein summations\n",
    "\n",
    "# compact representation for representing products and sums\n",
    "torch.einsum('ik, kj -> ikj', m1, m2)\n",
    "\n",
    "# if we instead want to sum automatically we can simply write\n",
    "torch.einsum('ik, kj -> ij', m1, m2)\n",
    "\n",
    "# MatMul\n",
    "\n",
    "# you can either do:\n",
    "#     torch.matmul or\n",
    "#     @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299ac0c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m             tmp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a[i, k] \u001b[38;5;241m*\u001b[39m b[k, j]\n\u001b[0;32m     16\u001b[0m         c[i,j] \u001b[38;5;241m=\u001b[39m tmp\n\u001b[1;32m---> 18\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(ar, bc)\n\u001b[0;32m     19\u001b[0m matmul((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), m1, m2, res)\n\u001b[0;32m     20\u001b[0m res\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# CUDA\n",
    "\n",
    "# you have to tell the GPU the things you want to do in parallel\n",
    "# you have to create a function that will do one thing\n",
    "\n",
    "# we can pick a single value taht we want to create and mat muul\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def matmul(a, b, c):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < c.shape[0] and j < c.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(a.shape[1]): \n",
    "            tmp += a[i, k] * b[k, j]\n",
    "        c[i,j] = tmp\n",
    "        \n",
    "res = torch.zeros(ar, bc)\n",
    "matmul((0, 0), m1, m2, res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb7a186",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grid_y): \n\u001b[0;32m      7\u001b[0m             kernel((i,j), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m----> 9\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(ar, bc)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# kernel will loop over all parts of the grid and pass on the args and kwargs we passed into it like the matrices and the zeroes matrix we created\u001b[39;00m\n\u001b[0;32m     11\u001b[0m launch_kernel(matmul, ar, bc, m1, m2, res)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "# we can call this function a kernel\n",
    "\n",
    "def launch_kernel(kernel, grid_x, grid_y, *args, **kwargs):\n",
    "    for i in range(grid_x):\n",
    "        for j in range(grid_y): \n",
    "            kernel((i,j), *args, **kwargs)\n",
    "            \n",
    "res = torch.zeros(ar, bc)\n",
    "# kernel will loop over all parts of the grid and pass on the args and kwargs we passed into it like the matrices and the zeroes matrix we created\n",
    "launch_kernel(matmul, ar, bc, m1, m2, res)\n",
    "res\n",
    "\n",
    "m1g, m2g, rg = map(cuda.to_device, (x_train, weights, r))\n",
    "# passing our data to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac6bf80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m1c, m2c \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mcuda(), weights\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      2\u001b[0m matrix \u001b[38;5;241m=\u001b[39m (m1c\u001b[38;5;129m@m2c\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "m1c, m2c = x_train.cuda(), weights.cuda()\n",
    "matrix = (m1c@m2c).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8130f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster analysis - trying to find groups of similar things within our data\n",
    "\n",
    "# Best used for when our columns and data and within the same kind of data and scale\n",
    "# For example we can use \n",
    "\n",
    "import math, matplotlib.pyplot as plt, operator, torch\n",
    "from functools import partial\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.set_printoptions(linewidth = 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 7\n",
    "n_samples = 180\n",
    "\n",
    "# generating centroids\n",
    "centroids = torch.rand(n_clusters, 2) * 70 - 35\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch import tensor\n",
    "\n",
    "def sample(m): \n",
    "    return MultivariateNormal(m, torch.diag(tensor([5.,5.]))).sample((n_samples,))\n",
    "\n",
    "\n",
    "slices = [sample(c) for c in centroids]\n",
    "data = torch.cat(slices)\n",
    "data.shape\n",
    "\n",
    "def plot_data(centroids, data, n_samples, ax=None):\n",
    "    if ax is None: _,ax = plt.subplots()\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        samples = data[i*n_samples:(i+1)*n_samples]\n",
    "        ax.scatter(samples[:,0], samples[:,1], s=1)\n",
    "        ax.plot(*centroid, markersize=10, marker=\"x\", color='k', mew=5)\n",
    "        ax.plot(*centroid, markersize=5, marker=\"x\", color='m', mew=2)\n",
    "        \n",
    "\n",
    "plot_data(centroids, data, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial in python allows for currying - thus creating a partially applied function\n",
    "# partial function applying is far more easy and quite simple you can pass parameters to the partial and is simple\n",
    "\n",
    "# For every thing possible point you take the distance from every single value to that one give value an then you apply this on a kernel\n",
    "# the gaussian with an effect being the standard deviation\n",
    "# then the centroids are the weighted averages\n",
    "\n",
    "# we can also batch mean shift clustering\n",
    "# There is a huge communication overhead - kernel launching overhead especially whenever you call cuda\n",
    "# with broadcasting we can easily apply lots of applications of batches\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
